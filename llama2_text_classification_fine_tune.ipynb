{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Fine-tuning Llama3 model on ChatDoctor dataset using PEFT, LORA and SFTTrainer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target of this project is to fine-tune Llama3 to generate physician-like responses to patient's queries. Llama3 will first be fine-tuned on the ChatDoctor dataset, which contains several thousand patient-physician interactions.\n",
    "\n",
    "We would like Llama3 responses to be comparable in the quality of medical advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "from src import process_text, utils\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "import logging\n",
    "\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_L3 = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load 3% of the 'lavita/ChatDoctor-HealthCareMagic-100k' dataset, then split it into train/val and test splits. \n",
    "\n",
    "*Note*: Loading the entire dataset and using it to fine-tune the Llama3 model can improve the fine-tuned model but model+data might not fit into our GPU RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\", split='train[:3%]')\n",
    "dev_test = dataset.train_test_split(test_size=0.2)\n",
    "train_valid = dev_test['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\":train_valid['train'],\n",
    "    \"validation\":train_valid['test'],\n",
    "    \"test\":dev_test['test'],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Example**\n",
    "Let us look at an example patient-physician interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "instruction\n",
      "If you are a doctor, please answer the medical questions based on the patient's description.\n",
      "\n",
      "input\n",
      "yes my son n law was puching my daughter in stomach to abort baby my daughter had been haing severe\n",
      "pain for 2 weeks through her body took her to 2 hospitals they refused to treat her due to her\n",
      "being pregnant so he calls said she need to go to doctor i got her to a hospital they took her in\n",
      "was not for sure what was going on and after she passed they said endocarditis which after she was\n",
      "buried when we find he been punching her.the baby did not have fluid around it,my daughter had\n",
      "infection over her entire body was coughing up blood chest pains rapid heart rate of 228do u think\n",
      "him punching her could cause the endocarditis?\n",
      "\n",
      "output\n",
      "Hi and pleased to answer you. Throughout pregnancy, the fetus bathes in a translucent pouch that\n",
      "gradually fills with amniotic fluid until the 35th week of amenorrhea where the amount of fluid is\n",
      "at its maximum with about 980 ml. Then the amniotic fluid decreases to the end to reach a volume\n",
      "between 600 and 800 ml approximately. The flow of the amniotic fluid signals the rupture of the\n",
      "membrane, and the risk of premature delivery if the term of the pregnancy is not reached. When the\n",
      "amount of amniotic fluid is abnormally low compared to the term of pregnancy, it is called\n",
      "oligoamnios. During oligoamnios, infection rate is higher. The premature rupture of the membranes\n",
      "(rupture before the beginning of the work) concerns 5 to 10% of the pregnancies. Its risk factors\n",
      "are the same as those of spontaneous preterm birth with intact membranes. This patient received a\n",
      "punch on her abdomen, which caused a premature rupture of the membranes and then a loss of the\n",
      "entirety amniotic fluid then an oligoamnios was created, and during the 2 weeks before the\n",
      "hospitalization, there was infection of the genital and baby components and infection dissemination\n",
      "by haematogenous route Causing endocarditis. Sorry for your daughter and may god has his soul in\n",
      "peace.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "example = dataset['train'][0]\n",
    "for key in example.keys():\n",
    "    print(f\"\\n{key}\")\n",
    "    lines = text_splitter.split_text(example[key])\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data points to alpaca format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25c7ed5d268439ebbe3746a56e239bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f596cee9ba4dd288bc02a63ecdcf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c150236c9744813b56fdd06da25651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_alpaca(data_point, deploy=False):\n",
    "    COMMAND = \"You are a doctor. Answer the following query by a patient.\"\n",
    "\n",
    "    #a_instruction = data_point['instruction']\n",
    "    a_input = data_point['input']\n",
    "    a_response = data_point['output']\n",
    "\n",
    "    if deploy:\n",
    "        training_prompt = f\"\"\"\n",
    "            ### Instruction:{COMMAND}\n",
    "            ### Input:{a_input}\n",
    "            ### Response:\n",
    "            \"\"\".strip()\n",
    "        example = {\n",
    "            \"question\":a_input,\n",
    "            \"answer\": a_response, \n",
    "            \"text\": training_prompt\n",
    "            }\n",
    "    else:\n",
    "        training_prompt = f\"\"\"\n",
    "            ### Instruction:{COMMAND}\n",
    "            ### Input:{a_input}\n",
    "            ### Response:{a_response}\n",
    "            \"\"\".strip()\n",
    "        example = {\n",
    "            \"question\":a_input,\n",
    "            \"answer\": a_response, \n",
    "            \"text\": training_prompt\n",
    "            }\n",
    "\n",
    "    return example\n",
    "\n",
    "for key in ['train', 'validation', 'test']:\n",
    "    dataset[key] = dataset[key].shuffle(seed=42).map(to_alpaca)\n",
    "    #.remove_columns(['input', 'output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Model Creation** \n",
    "Create and initialize the model, tokenizer with PEFT, LORA and BitsAndBytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating model meta-llama/Meta-Llama-3-8B-Instruct..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2ca3ba8a4046a1b8324314c22208d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model and tokenizer\n",
    "llm3, tokenizer = utils.create_model_and_tokenizer(MODEL_L3)\n",
    "lora_r = 16\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\",\"v_proj\"]\n",
    " \n",
    "# LORA and training arguments\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431c7ad1a67f4e0a976c0051dd4c8738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39432e264ef4e68926e16a657c01527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"experiments/text_classification\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=llm3,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1076' max='1076' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1076/1076 1:59:36, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2.304200</td>\n",
       "      <td>2.333785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>2.157200</td>\n",
       "      <td>2.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>2.076300</td>\n",
       "      <td>2.255844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>1.994600</td>\n",
       "      <td>2.242996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "\n",
    "# Official method: Saves adapted and base separately\n",
    "base_model_name = MODEL_L3\n",
    "adapter_model_name = OUTPUT_DIR\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "model = PeftModel.from_pretrained(model, adapter_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "\n",
    "# Method 2: Saves merged model (which is huge)\n",
    "'''model = PeftModel.from_pretrained(model, OUTPUT_DIR)\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"merged_model\", safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_model\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Deployment**\n",
    "Deploy the fine-tuned model on test set and check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a127765f834d848c54fddd344f55b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the base model and fine-tuned model\n",
    "\n",
    "OUTPUT_DIR = \"experiments/text_classification/checkpoint-1000\"\n",
    "base_model_name = MODEL_L3\n",
    "adapter_model_name = OUTPUT_DIR\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    #bnb_4bit_compute_dtype=\"bf16\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name, \n",
    "    device_map=\"auto\",\n",
    "    use_safetensors=True,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True)\n",
    "\n",
    "#model = PeftModel.from_pretrained(model, adapter_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:peft.tuners.tuners_utils:Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(model, adapter_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "llm_answers = []\n",
    "\n",
    "# used for inference\n",
    "def summarize(model, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.0001)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
    "\n",
    "# run model on some examples from test set\n",
    "for data_point in dataset[\"test\"].select(range(5)):\n",
    "    examples.append(to_alpaca(data_point, deploy=True))\n",
    "\n",
    "test_df = pd.DataFrame(examples)\n",
    "\n",
    "for idx in range(5):\n",
    "    example = test_df.iloc[idx]\n",
    "    llm_answers.append(summarize(model, example.text)) # have to make sure what is returned is answer, not entire output\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Llama3 Response vs Physician's Response**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate the performance of Llama3 fine-tuned model against physician's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient's Question:\n",
      "I am a male 79 years old, have brief chills the may sweat have had for about 2 months also white\n",
      "blood cell count to high had bone marrow test and ok so far dr has no idea what is wrong when I\n",
      "chill have no fever as I check that and blood pressure. thanks\n",
      "\n",
      "AI response:\n",
      "Thank you for sharing your symptoms with me. It's good to know that your blood work and bone marrow\n",
      "test came back normal.\n",
      "Based on your symptoms of brief chills and sweating, I would like to investigate further. I would\n",
      "like to perform a thorough physical examination, including checking your vital signs, such as your\n",
      "blood pressure, pulse, and respiratory rate.\n",
      "Additionally, I would like to order some additional tests to help us better understand what's going\n",
      "on. These tests may include a complete blood count, a urinalysis, and possibly some imaging\n",
      "studies, such as a chest X-ray or a computed tomography (CT) scan.\n",
      "Please let me know if you have any questions or concerns about these tests or any other aspect of\n",
      "your care. I am here to help you and to ensure that you receive the best possible care. Thank you\n",
      "for entrusting your care to me. I am here to help you. Please let me know if you have any questions\n",
      "or concerns about your care. I am here to help you and to ensure that you receive the best possible\n",
      "care. Thank you for entrusting your care to me. I am here to help you. Please let me know if you\n",
      "have any questions or concerns about your care. I am here to help you and to\n",
      "\n",
      "Physician's response:\n",
      "Hi, From history it seems that you require evaluation of your case. As you get chills often and WBC\n",
      "is high it indicates there might be having some infection in your body giving this problem. Consult\n",
      "your doctor and go for,1, X-ray chest,2, ultrasound abdomen,3, complete urine check up.4, Blood\n",
      "checking for RFT, LFT and other tests. After all reports, one can have clue about your problem, and\n",
      "then they will go for treatment accordingly. Ok and take care.\n",
      "Patient's Question:\n",
      "I was diagnosed a few years ago with borderline personality disorder, anxiety and depression, I have\n",
      "taken antidepressants forever since I was in my 20s I am now 39. I have had a lot of traumatic\n",
      "things happen in my life, My dad committed suicide today would have been his birthday. I have been\n",
      "abused in every way and I am trying to get my life back. For many years Ive had no libido, no joy\n",
      "in my life.  Ive missed bdays anniversaries weddings etc. All because I felt depressed and didnt\n",
      "want to leave my house. Ive missed so may things, I have this. I have just been weaned of celexa\n",
      "4omg which I took for years with the Seroquel. My meds now are wellbutron xl 150mg, I started this\n",
      "pill less than two weeks ago, I have increased the dose to 150mg twice a day, I also take Seroquel\n",
      "at night. I have read so many testimonies on these meds and I am concerned. I have been getting\n",
      "severe stomach aches as well as feeling a slightly spaced out. Im wondering if I should stop taking\n",
      "wellbutron and Seroquel and asking my dr to put me back on celexa. Do I have to take meds for\n",
      "life??? How does a dr really know if you have mental illness couldnt it just be due to life\n",
      "experiences and the need to get past them? I feel like I am stupid or labeled and its embarrassing,\n",
      "I just want my life back. I have no joy at all.\n",
      "\n",
      "AI response:\n",
      "Dear patient, I understand your concerns and frustrations. It's completely normal to feel this way,\n",
      "especially when dealing with mental health issues.\n",
      "Firstly, let me assure you that you are not stupid or labeled. Mental health issues are not a\n",
      "reflection of one's intelligence or worth.\n",
      "Regarding your concerns about taking meds for life, it's true that some people may need to take\n",
      "medication for an extended period. However, it's also important to note that medication is not a\n",
      "one-size-fits-all solution. Your doctor will work with you to find the right medication and dosage\n",
      "for your specific needs.\n",
      "Regarding your concerns about getting past life experiences and the need to get past them, it's\n",
      "true that life experiences can shape our perspectives and influence our mental health. However,\n",
      "it's also important to note that it's possible to work through and overcome the challenges posed by\n",
      "life experiences. Your doctor can help you develop coping strategies and work through the\n",
      "challenges you're facing.\n",
      "I hope this helps you feel more understood and supported. Remember, you are not alone in this\n",
      "journey. Your doctor is here to support you and help you find the right path forward. Keep in mind\n",
      "that it's okay to take things one step at a time. You don't have to have all the answers right now\n",
      "\n",
      "Physician's response:\n",
      "Hi, Firstly borderline personality disorder (BPD), makes a person vulnerable for mental illnesses.\n",
      "The thought processes that a person with BPD has is quite different from that of a person without\n",
      "the disorder, and it makes it difficult for the person to cope with day to day stresses that every\n",
      "human being faces in their life. Patients with BPD tend to suffer from complications involving\n",
      "mental health with the slightest of stress. And as you mention, what you have gone through is much\n",
      "more than usual. Coming to your query, why can't this be a normal reaction? Now, if a person\n",
      "without BPD or with no vulnerability happens to go through these experiences then the outcome would\n",
      "depend on his coping skills. Excellent coping skills \\u2192 Brief period to recover and no illness.\n",
      "Poor coping skills \\u2192 mental illness. The symptoms of loss of interest inability to feel joy\n",
      "and low mood for many years is a sign of a mental illness. But it is great that you want to come\n",
      "out of it. There are many ways. Medications being one of them. Adequate medications usually help\n",
      "control these symptoms. There are additional treatments that can benefit you which is psychotherapy\n",
      "that involves, building a positive outlook and personality transformation etc. This helps in\n",
      "building coping skills as well. Trained psychologists administer them. They are known to be useful\n",
      "in cases of BPD apart from medication. It takes a minimum of 2 weeks to determine whether a Chat\n",
      "Doctor.  I do not know the reason for switching your antidepressant but if the recent\n",
      "Patient's Question:\n",
      "Hi, I injected my self with Clexane a return from holiday 12 days ago. I had a P.E 6 years ago.I am\n",
      "having to have oral surgery shortly, would the effects,(blood thinning) have worn off by now? So\n",
      "would it be OK to go ahead with the surgery at this time? An early response would be greatly\n",
      "appreciated.\n",
      "\n",
      "AI response:\n",
      "Dear patient,\n",
      "Thank you for reaching out to me with your concerns. I understand that you have been\n",
      "taking Clexane for 12 days now, and you are wondering if the effects of blood thinning have worn\n",
      "off by now.\n",
      "Firstly, it's important to note that the effects of Clexane can vary depending on individual\n",
      "factors, such as body weight, age, and medical history.\n",
      "However, based on the information you provided, it's likely that the effects of Clexane have not\n",
      "yet worn off. The medication is designed to be effective for a certain period of time, and it's not\n",
      "uncommon for the effects of blood thinning medications like Clexane to persist for several weeks\n",
      "after the medication is stopped.\n",
      "In your case, since you are scheduled to have oral surgery shortly, it's important to discuss your\n",
      "medication regimen with your oral surgeon. They will be able to assess your individual situation\n",
      "and provide guidance on how to manage your medication regimen in the context of your upcoming oral\n",
      "surgery.\n",
      "I hope this information is helpful. Please don't hesitate to reach out to me if you have any\n",
      "further questions or concerns.\n",
      "\n",
      "Physician's response:\n",
      "Welcome to Chat Doctor. I am Chat Doctor. Dear friend, Clean has half-life of approximately 4.4\n",
      "hours for a dose of 40 mg.  Clean activity may persist in the plasma for 24 hours. After 12 days\n",
      "its level in blood is negligible. You have to do one blood test PT INR. This blood test will be\n",
      "very helpful for further management and plan for oral surgery. I suggest you to take Clean in\n",
      "proper doctor guidance with regular PT INR test. Thanx for query.\n",
      "Patient's Question:\n",
      "6 year old male diagnosed with high lead levels. has been treated with chelation intramuscularly and\n",
      "then with the medication given by mouth. level receded to high normal level for one month. current\n",
      "blood test shows a significant elevation and the chelation medication is to be started again this\n",
      "evening. are there any other suggestions that you can make as far as treatment to permanently\n",
      "diminish this problem to a safe level. surroundings, toys, etc. have all been tested and show no\n",
      "lead content that is harmful.\n",
      "\n",
      "AI response:\n",
      "Thank you for your query. I understand your concern about the high lead levels in your son. I'm glad\n",
      "to hear that the chelation medication has been effective in reducing the lead levels to a high\n",
      "normal level.\n",
      "As for your question about other suggestions for treatment to permanently diminish the problem to a\n",
      "safe level, I would recommend the following:\n",
      "1. Continue the chelation medication as prescribed by your doctor.\n",
      "2. Ensure that your son's environment is lead-free. This includes toys, furniture, and other\n",
      "household items.\n",
      "3. Consider having your son's home tested for lead. This can help identify any potential sources of\n",
      "lead in the home.\n",
      "4. Educate yourself and your son about the dangers of lead poisoning and the importance of taking\n",
      "steps to prevent it.\n",
      "I hope this information is helpful. Please let me know if you have any further questions.\n",
      "\n",
      "Physician's response:\n",
      "Thanks for your query on ChatDoctorFrom history its seems this child is having chronic lead exposure\n",
      "and lead toxicity. Its treatment include 1. Identification of source of exposure. It may be due to\n",
      "eating soil, paint, some herbal remedies etc.2. Behavioral modification to reduce non-nutritive\n",
      "eating habits.3. Dietary counselings to insure sufficient intake of essential elements calcium and\n",
      "iron.4. Chelation therapy to decrease lead level Hope this information will help. For more queries\n",
      "you may contact me at this site. Regards- Chat Doctor.\n",
      "Patient's Question:\n",
      "I randomly get a flutter in the middle of my chest.  It almost feels like a fish flipped flopped\n",
      "inside me.  The flutter is not accompanied by any pain, but I do feel it takes by breath away.  I\n",
      "have had numerous EGKs done and they have are been normal.  The flutter, could that be a muscle\n",
      "that is just spasaming?\n",
      "\n",
      "AI response:\n",
      "Thank you for coming to see me. I'm glad you're here to get some answers.\n",
      "First, let me tell you that the flutter you're experiencing is not a muscle spasm. While it's\n",
      "possible that a muscle spasm could cause a fluttering sensation, the fact that you're experiencing\n",
      "this sensation in the middle of your chest, without any pain, suggests that there may be a more\n",
      "complex underlying cause.\n",
      "I would like to order some additional tests to help us better understand what's going on. These\n",
      "tests may include an electrocardiogram (ECG), a chest X-ray, and possibly an echocardiogram (ECHO)\n",
      "or a cardiac MRI.\n",
      "I would also like to discuss some lifestyle changes that may help alleviate your symptoms. These\n",
      "may include reducing your stress levels, getting regular exercise, and maintaining a healthy diet.\n",
      "I hope this helps, and I look forward to discussing these further with you. Do you have any\n",
      "questions or concerns about what I've discussed so far?\n",
      "\n",
      "Physician's response:\n",
      "Thanks for your question on Chat Doctor. I can understand your concern. No need to worry about\n",
      "cardiac diseases because your multiple ECG s are normal. Possibility of involuntary muscular\n",
      "contractions is more in your case. Common causes for this are low calcium and magnesium level. So\n",
      "get done serum calcium and magnesium level. If deficiency than you need supplements. If both are\n",
      "normal than sometimes stress and anxiety can also cause fluttering sensation in chest. So avoid\n",
      "stress and tension. Be relax and calm. Don't worry, you will be alright. First rule out calcium and\n",
      "magnesium deficiency. Hope I have solved your query. Wish you good health. Thanks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "q_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    example = test_df.iloc[i]\n",
    "    print(\"\\nPatient's Question:\")\n",
    "    for q in q_splitter.split_text(example.question):\n",
    "        print(q)\n",
    "\n",
    "    print(\"\\nAI response:\")\n",
    "    for line in text_splitter.split_text(llm_answers[i]):\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nPhysician's response:\")\n",
    "    for line in text_splitter.split_text(example.answer):\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
